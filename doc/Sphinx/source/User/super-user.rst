Super User
+++++++++++++++++++++++

The Dataverse Network provides several options for configuring and
customizing your application. To access these options, login to the
Dataverse Network application with an account that has Network
Administrator privileges. By default, a brand new installation of the
application will include an account of this type - the username and
password is 'networkAdmin'.

After you login, the Dataverse Network home page links to the Options
page from the "Options" gear icon, in the menu bar. Click on the icon to
view all the options available for customizing and configuring the
applications, as well as some network adminstrator utilities.

The following tasks can be performed from the Options page:

-  Manage dataverses, harvesting, exporting, and OAI sets - Create,
   edit, and manage standard and harvesting dataverses, manage
   harvesting schedules, set study export schedules, and manage OAI
   harvesting sets.
-  Customize the Network pages and description - Brand your Network and
   set up your Network e-mail contact.
-  Set and edit Terms of Use - Apply Terms of Use at the Network level
   for accounts, uploads, and downloads.
-  Create and manage user accounts and groups and Network privileges,
   and enable option to create a dataverse - Manage logins, permissions,
   and affiliate access to the Network.
-  Use utilities and view software information - Use the administrative
   utilities and track the current Network installation.

Dataverses Section
====================

Create a New Dataverse
-------------------------

A dataverse is a container for studies and is the home for an individual
scholar's or organization's data.

Creating a dataverse is easy but first you must be a registered user.
Depending on site policy, there may be a link on the Network home page,
entitled "Create a Dataverse". This first walks you through creating an
account, then a dataverse. If this is not the case on your site, log in,
then navigate to the Create a New Dataverse page and complete the
required information. That's it!

#. Navigate to the Create a New Dataverse page: 
    Network home page > Options page >Dataverses tab > Dataverse subtab > "Create Dataverse" link.
#. Fill in the required information:


    **Type of Dataverse**


    Choose Scholar if it represents an individual's work otherwise choose Basic.


    **Dataverse Name**


    This will be displayed on the network and dataverse home
    pages. If this is a Scholar dataverse it will automatically be
    filled in with the scholar's first and last name.


    **Dataverse Alias**


    This is an abbreviation, usually lower-case, that becomes part of the URL for the new dataverse.
#. Click Save and you're done!

   An email will be sent to you with more information, including
   the url to access you new dataverse.

**Required information** can vary depending on site policy. Required fields are noted with a red asterisk.

Note: If "Allow users to create a new Dataverse when they create an account" is enabled, there is a Create a Dataverse link on the Network home page.

Manage Dataverses
--------------------

As dataverses increase in number it's useful to view summary information
in table form and quickly locate a dataverse of interest. The Manage
Dataverse table does just that.

Navigate to Network home page > Options page > Dataverses tab >
Dataverses subtab > Manage Dataverse table:

-  Dataverses are listed in order of most recently created.
-  Clicking on a column name sorts the list by that column such as Name
   or Affiliation.
-  Clicking on a letter in the alpha selector displays only those
   dataverses beginning with that letter.
-  Move through the list of dataverses by clicking a page number or the
   forward and back buttons.
-  Click Delete to remove a dataverse.

Manage Classifications
------------------------

Classifications are a way to organize dataverses on the network home
page so they are more easily located. They appear on the left side of
the page and clicking on a classification causes corresponding
dataverses to be displayed. An example classification might be
Organization, Government.

Classifications typically form a hierarchy defined by the network
administrator to be what makes sense for a particular site. A top level
classification could be Organization, the next level Association,
Business, Government, and School.

The classification structure is first created on the Options page, from
the Manage Classifications table. Once a classification is created,
dataverses can be assigned to it either when the dataverse is first
created or later from the Options page: Network home page > (Your)
Dataverse home page > Options page > Settings tab > General subtab.

To manage classifications, navigate to the Manage Classifications table:

Network home page > Options page > Classifications tab > Manage
Classifications table

From here you can view the current classification hierarchy, create a
classification, edit an existing classification including changing its
place in the hierarchy, and delete a classification.

Manage Study Comments Notifications
---------------------------------------

Dataverse admins can enable or disable a User Comment feature within
their dataverses. If this feature is enabled, users are able to add
comments to studies within that dataverse. Part of the User Comment
feature is the ability for users to report comments as abuse if they
deem that comment to be inappropriate in some way.

Note that it is a best practice to explicitly define terms of use
regarding comments when the User Comments feature is enabled. If you
define those terms at the Network level, then any study to which
comments are added include those terms.

When a user reports another's comment as abuse, that comment is listed
on the Manage Study Comment Notifications table on the Options page. For
each comment reported as abuse, you see the study's Global ID, the
comment reported, the user who posted the comment, and the user who
reported the comment as abuse.

There are two ways to manage abuse reports: In the Manage Study Comment
Notifications table on the Options page, and on the study page User
Comments tab. In both cases, you have the options to remove the comment
or to ignore the abuse report.

The Manage Study Comments Notifications table can be found here:

Network home page > Options page > Dataverses tab > Study Comments
subtab > Manage Study Comment Notifications table

Manage Controlled Vocabulary
----------------------------------

You can set up controlled vocabulary for a dataverse network to give the
end user a set list of choices to select from for most fields in a study
template. Study fields which do not allow controlled vocabulary include
the study title and subtitle, certain date fields and geographic
boundaries.

To **manage controlled vocabulary**, navigate to the Manage Controlled
Vocabulary table:

``Network home page > Options page > Vocabulary tab > Manage Controlled Vocabulary table``


**To create a new controlled vocabulary:**

#. Click Create New Controlled Vocabulary.
#. You see the Edit Controlled Vocabulary page.
#. In the Name field, enter a descriptive name for this Controlled
   Vocabulary. In the Description field enter any additional information
   that will make it easier to identify a particular controlled
   vocabulary item to assign to a given custom field. In the Values
   field enter the controlled vocabulary values that you want to make
   available to users for a study field. Use the plus and minus buttons
   to add or subtract values from the list.
#. After you complete entry of values, click Save to create the
   controlled vocabulary.

**Edit Controlled Vocabulary**


To edit an existing controlled vocabulary:

#. In the list of controlled vocabulary, click the Edit link for the
   controlled vocabulary that you choose to edit. You see the Edit
   Controlled Vocabulary page, with the controlled vocabulary setup that
   you selected.
#. Edit the controlled vocabulary items that you choose to change, add,
   or remove.

Manage Network Study Templates
-------------------------------------

You can set up study templates for a dataverse network to prepopulate
any of the Cataloging Information fields of a new study with default
values. Dataverse administrators may clone a Network template and modify
it for users of that dataverse. You may also change the input level of
any field to make a certain field required, recommended, optional,
hidden or disabled. Hidden fields will not be available to the user, but
will be available to the dataverse administrator for update in cloned
templates. Disabled field will not be available to the dataverse
administrator for update. You may also add your own custom fields. When
a user adds a new study, that user can select a template to fill in the
defaults.

To manage study templates, navigate to the Manage Study Templates table:

``Network home page > Options page > Templates tab > Manage Study Templates table``


**Create Template**

Study templates help to reduce the work needed to add a study, and to
apply consistency to studies across a dataverse network. For example,
you can create a template to include the Distributor and Contact details
so that every study has the same values for that metadata.

To create a new study template:

#. Click Create New Network Template.
#. You see the Study Template page.
#. In the Template Name field, enter a descriptive name for this
   template.
#. Enter generic information in any of the Cataloging Information
   metadata fields. You can also add your own custom fields to the Data
   Collection/Methodology section of the template. Each custom field
   must be assigned a Name, Description and Field Type. You may also
   apply controlled vocabulary to any of the custom fields that are set
   to Plain Text Input as Field Type.
#. After you complete entry of generic details in the fields that you
   choose to prepopulate for new studies, click Save to create the
   template.

**Enable a template**

Click the Enabled link for the given template. Enabled templates are
available to database administrators for cloning and end users for
creating studies.


**Edit Template**

To edit an existing study template:

#. In the list of templates, click the Edit link for the template that
   you choose to edit.
#. You see the Study Template page, with the template setup that you
   selected.
#. Edit the template fields that you choose to change, add, or remove.

**Make a Template the Default**

To set any study template as the default template that applies
automatically to the creation of new network templates:


In the list of templates, click the Make Default link next to the name
of the template that you choose to set as the default. The Default label
is displayed in the Default column of the template that you set as the
default.

**Remove Template**

To delete a study template from a dataverse:

#. In the list of templates, click the Delete link for the template that
   you choose to remove from the network.
#. You see the Delete Template page.
#. Click Delete to remove the template from the network. Note that you
   cannot delete any template that is in use or is a default template at
   the network or dataverse level.

Harvesting Section
=======================

Create a New Harvesting Dataverse
------------------------------

A harvesting dataverse allows studies from another site to be imported
so they appear to be local, though data files remain on the remote site.
This makes it possible to access content from data repositories and
other sites with interesting content as long as they support the OAI or
Nesstar protocols.

Harvesting dataverses differ from ordinary dataverses in that study
content cannot be edited since it is provided by a remote source. Most
dataverse functions still apply including editing the dataverse name,
branding, and setting permissions.

Aside from providing the usual name, alias, and affiliation information,
Creating a harvesting dataverse involves specifying the harvest
protocol, OAI or Nesstar, the remote server URL, possibly format and set
information, whether or how to register incoming studies, an optional
harvest schedule, and permissions settings.

To create a harvesting dataverse navigate to the Create a New Harvesting
Dataverse page:

``Network home page > Options page > Harvesting tab > Harvesting Dataverses subtab > "Create Harvesting Dataverse" link``

Complete the form by entering required information and click Save.

An example dataverse to harvest studies native to the Harvard dataverse:

- **Harvesting Type:** OAI Server
- **Dataverse Name:** Test IQSS Harvest
- **Dataverse Alias:** testiqss
- **Dataverse Affiliation:** Our Organization
- **Server URL:** `http://dvn.iq.harvard.edu/dvn/OAIHandler <http://dvn.iq.harvard.edu/dvn/OAIHandler>`__
- **Harvesting Set:** No Set (harvest all)
- **Harvesting Format:** DDI
- **Handle Registration:** Do not register harvested studies (studies must already have a handle)

Manage Harvesting
--------------------

Harvesting is a background process meaning once initiated, either
directly or via a timer, it conducts a transaction with a remote server
and exists without user intervention. Depending on site policy and
considering the update frequency of remote content this could happen
daily, weekly, or on-demand. How does one determine what happened? By
using the Manage Harvesting Dataverses table on the Options page.

To manage harvesting dataverses, navigate to the **Manage Harvesting
Dataverses** table:

``Network home page > Options page > Harvesting tab > Harvesting Dataverses subtab > Manage Harvesting Dataverses table``

The Manage Harvesting table displays all harvesting dataverses, their
schedules, and harvest results in table form. The name of each
harvesting dataverse is a link to that harvesting dataverse's
configuration page. The schedule, if configured, is displayed along with
a button to enable or disable the schedule. The last attempt and result
is displayed along with the last non-zero result. It is possible for the
harvest to check for updates and there are none. A Run Now button
provides on-demand harvesting and a Remove link deletes the harvesting
dataverse.

Note: the first time a dataverse is harvested the entire catalog is
harvested. This may take some time to complete depending on size.
Subsequent harvests check for additions and changes or updates.

Harvest failures can be investigated by examining the import and server
logs for the timeframe and dataverse in question.

Schedule Study Exports
------------------------

Sharing studies programmatically or in batch such as by harvesting
requires information about the study or metadata to be exported in a
commonly understood format. As this is a background process requiring no
user intervention, it is common practice to schedule this to capture
updated information.

Our export process generates DDI, Dublin Core, Marc, and FGDC formats
though DDI and Dublin Core are most commonly used. Be aware that
different formats contain different amounts of information with DDI
being most complete because it is our native format.

To schedule study exports, navigate to the Harvesting Settings subtab:

``Network home page > Options page > Harvesting tab > Settings subtab > Export Schedule``

First enable export then choose frequency: daily using hour of day or
weekly using day of week. Click Save and you are finished.

To disable, just choose Disable export and Save.

Manage OAI Harvesting Sets
-----------------------------

By default, a client harvesting from the Dataverse Network that does not
specify a set would fetch all unrestricted, locally owned
studies - in other words public studies that were not harvested
from elsewhere. For various reasons it might be desirable to define sets
of studies for harvest such as by owner, or to include a set that was
harvested from elsewhere. This is accomplished using the Manage OAI
Harvesting Sets table on the Options page.

The Manage OAI Harvesting Sets table lists all currently defined OAI
sets, their specifications, and edit, create, and delete functionality.

To manage OAI harvesting sets, navigate to the Manage OAI Harvesting
Sets table:

``Network home page > Options page > Harvesting tab > OAI Harvesting Sets subtab > Manage OAI Harvesting Sets table``

To create an OAI set, click Create OAI Harvesting Set, complete the
required fields and Save. The essential parameter that defines the set
is the Query Definition. This is a search query using `Lucene
syntax <http://lucene.apache.org/java/3_0_0/queryparsersyntax.html>`__
whose results populate the set.

Once created, a set can later be edited by clicking on its name.

To delete a set, click the appropriately named Delete Set link.

To test the query results before creating an OAI set, a recommended
approach is to create a :ref:`dynamic study
collection <manage-collections>` using the
proposed query and view the collection contents. Both features use the
same `Lucene
syntax <http://lucene.apache.org/java/3_0_0/queryparsersyntax.html>`__
but a study collection provides a convenient way to confirm the results.

Generally speaking, basic queries take the form of study metadata
field:value. Examples include:

- ``globalId:"hdl 1902 1 10684" OR globalId:"hdl 1902 1 11155"``: Include studies with global ids hdl:1902.1/10684 and
  hdl:1902.1/11155
- ``authority:1902.2``: Include studies whose authority is 1902.2. Different authorities usually represent different sources such
  as IQSS, ICPSR, etc.
- ``dvOwnerId:184``: Include all studies belonging to dataverse with database id 184 
- ``studyNoteType:"DATAPASS"``: Include all studies that were tagged with or include the text DATAPASS in their study note field.

**Study Metadata Search Terms:**

| title
| subtitle
| studyId
| otherId
| authorName
| authorAffiliation
| producerName
| productionDate
| fundingAgency
| distributorName
| distributorContact
| distributorContactAffiliation
| distributorContactEmail
| distributionDate
| depositor
| dateOfDeposit
| seriesName
| seriesInformation
| studyVersion
| relatedPublications
| relatedMaterial
| relatedStudy
| otherReferences
| keywordValue
| keywordVocabulary
| topicClassValue
| topicClassVocabulary
| abstractText
| abstractDate
| timePeriodCoveredStart
| timePeriodCoveredEnd
| dateOfCollection
| dateOfCollectionEnd
| country
| geographicCoverage
| geographicUnit
| unitOfAnalysis
| universe
| kindOfData
| timeMethod
| dataCollector
| frequencyOfDataCollection
| samplingProcedure
| deviationsFromSampleDesign
| collectionMode
| researchInstrument
| dataSources
| originOfSources
| characteristicOfSources
| accessToSources
| dataCollectionSituation
| actionsToMinimizeLoss
| controlOperations
| weighting
| cleaningOperations
| studyLevelErrorNotes
| responseRate
| samplingErrorEstimate
| otherDataAppraisal
| placeOfAccess
| originalArchive
| availabilityStatus
| collectionSize
| studyCompletion
| confidentialityDeclaration
| specialPermissions
| restrictions
| contact
| citationRequirements
| depositorRequirements
| conditions
| disclaimer
| studyNoteType
| studyNoteSubject
| studyNoteText

Edit LOCKSS Harvest Settings
-----------------------------

**Summary:**

`LOCKSS Project <http://lockss.stanford.edu/lockss/Home>`__ or *Lots
of Copies Keeps Stuff Safe* is an international initiative based at
Stanford University Libraries that provides a way to inexpensively
collect and preserve copies of authorized e-content. It does so using an
open source, peer-to-peer, decentralized server infrastructure. In order
to make a LOCKSS server crawl, collect and preserve content from a Dataverse Network,
both the server (the LOCKSS daemon) and the client (the Dataverse Network) sides must
be properly configured. In simple terms, the LOCKSS server needs to be
pointed at the Dataverse Network, given its location and instructions on what to
crawl; the Dataverse Network needs to be configured to allow the LOCKSS daemon to
access the data. The section below describes the configuration tasks
that the Dataverse Network administrator will need to do on the client side. It does
not describe how LOCKSS works and what it does in general; it's a fairly
complex system, so please refer to the documentation on the `LOCKSS Project <http://lockss.stanford.edu/lockss/Home>`__\  site for more
information. Some information intended to a LOCKSS server administrator
is available in the `"Using LOCKSS with Dataverse Network (DVN)"
<http://guides.thedata.org/book/h-using-lockss-dvn>`__  of the
`Dataverse Network Installers Guide <http://guides.thedata.org/book/installers-guides>`__
 (our primary sysadmin-level manual). 

**Configuration Tasks:**

Note that neither the standard LOCKSS Web Crawler, nor the OAI plugin
can properly harvest materials from a Dataverse Network.  A custom LOCKSS plugin
developed and maintained by the Dataverse Network project is available here:
`http://lockss.hmdc.harvard.edu/lockss/plugin/DVNOAIPlugin.jar <http://lockss.hmdc.harvard.edu/lockss/plugin/DVNOAIPlugin.jar>`__.
For more information on the plugin, please see the `"Using LOCKSS with
Dataverse Network (DVN)" <http://guides.thedata.org/book/h-using-lockss-dvn>`__ section of
the Dataverse Network Installers Guide. In order for a LOCKSS daemon to collect DVN
content designated for preservation, an Archival Unit must be created
with the plugin above. On the Dataverse Network side, a Manifest must be created that
gives the LOCKSS daemon permission to collect the data. This is done by
completing the "LOCKSS Settings" section of the:
``Network Options -> Harvesting -> Settings tab.``

For the Dataverse Network, LOCKSS can be configured at the network level
for the entire site and also locally at the dataverse level. The network
level enables LOCKSS harvesting but more restrictive policies, including
disabling harvesting, can be configured by each dataverse. A dataverse
cannot enable LOCKSS harvesting if it has not first been enabled at the
network level.

This "Edit LOCKSS Harvest Settings" section refers to the network level
LOCKSS configuration.

To enable LOCKSS harvesting at the network level do the following:

- Navigate to the LOCKSS Settings page: ``Network home page -> Network Options -> Harvesting -> Settings``.
- Fill in the harvest information including the level of harvesting allowed (Harvesting Type, Restricted Data Files), the scope
  of harvest by choosing a predefined OAI set, then if necessary a list of servers or domains allowed to harvest.
- It's important to understand that when a LOCKSS daemon is authorized
  to "crawl restricted files", this does not by itself grant the actual
  access to the materials! This setting only specifies that the daemon
  should not be skipping such restricted materials outright. (The idea
  behind this is that in an archive with large amounts of
  access-restricted materials, if only public materials are to be
  preserved by LOCKSS, lots of crawling time can be saved by instructing
  the daemon to skip non-public files, instead of having it try to access
  them and get 403/Permission Denied). If it is indeed desired to have
  non-public materials collected and preserved by LOCKSS, it is the
  responsibility of the DVN Administrator to give the LOCKSS daemon
  permission to access the files. As of DVN version 3.3, this can only be
  done based on the IP address of the LOCKSS server (by creating an
  IP-based user group with the appropriate permissions).
- Next select any licensing options or enter additional terms, and click "Save Changes". 
- Once LOCKSS harvesting has been enabled, the LOCKSS Manifest page will
  be provided by the application. This manifest is read by LOCKSS servers
  and constitutes agreement to the specified terms. The URL for the
  network-level LOCKSS manifest is
  ``http``\ ``://<YOUR SERVER>/dvn/faces/ManifestPage.xhtml`` (it will be
  needed by the LOCKSS server administrator in order to configure an
  *Archive Unit* for crawling and preserving the DVN).

Settings Section
==================

Edit Name
-----------------

The name of your Dataverse Network installation is displayed at the top
of the Network homepage, and as a link at the top of each dataverse
homepage in your Network.

To create or change the name of your Network, navigate to the Settings
tab on the Options page:

``Network home page > Options page > Settings tab > General subtab > Network Name``

Enter a descriptive title for your Network. There are no naming
restrictions, but it appears in the heading of every dataverse in your
Network, so a short name works best.

Click Save and you are done!

Edit Layout Branding
-------------------------

When you install a Network, there is no banner or footer on any page in
the Network. You can apply any style to the Network pages, such as that
used on your organization's website. You can use plain text, HTML,
JavaScript, and style tags to define your custom banner and footer. If
your website has such elements as a navigation menu or images, you can
add them to your Network pages.

To customize the layout branding of your Network, navigate to the
Customization subtab on the Options page:

Network home page > Options page > Settings tab > Customization subtab >
Edit Layout Branding

Enter your banner and footer content in the Custom Banner and Custom
Footer fields and Save.

See :ref:`Layout Branding Tips <edit-layout-branding>` for guidelines.

Edit Description
---------------------

By default your Network homepage has the following description:
``A description of your Dataverse Network or announcements may be added here. Use Network Options to edit or remove this text.``
You can edit that text to describe or announce such things as new
Network features, new dataverses, or maintenance activities. You also
can disable the description to not appear on the homepage.

To manage the Network description, navigate to:

``Network home page > Options page > Settings tab > General subtab > Network Description``

Create a description by entering your desired content in the text box.
HTML, JavaScript, and style tags are permitted. The ``html`` and
``body`` element types are not allowed. Next enable the description
display by checking the Enable Description in Homepage checkbox. Click
Save and you're done. You can disable the display of the description but
keep the content by unchecking and saving.

Edit Dataverse Requirements
----------------------------

Enforcing a minimum set of requirements can help ensure content
consistency.

When you enable dataverse requirements, newly created dataverses cannot
be made public or released until the selected requirements are met.
Existing dataverses are not affected until they are edited. Edits to
existing dataverses cannot be saved until requirements are met.

To manage the requirements, navigate to:

``Network home page > Options page > Settings tab > Advanced subtab > Release Dataverse Requirements``

Available requirements include:

-  Require Network Homepage Dataverse Description
-  Require Dataverse Affiliation
-  Require Dataverse Classification
-  Require Dataverse Studies included prior to release

Manage E-Mail Notifications
---------------------------

The Dataverse Network sends notifications via email for a number of
events on the site, including workflow events such as creating a
dataverse, uploading files, releasing a study, etc. Many of these
notifications are sent to the user initiating the action as well as to
the network administrator. Additionally, the Report Issue link on the
network home page sends email to the network administrator. By default,
this email is sent to
`support@thedata.org <mailto:support@thedata.org>`.

To change this email address navigate to the Options page:

``Network home page > Options page > Settings tab > General subtab > E-Mail Address(es)``

Enter the address of network administrators who should receive these
notifications and Save.

Please note the Report Issue link when accessed within a dataverse gives
the option of sending notification to the network or dataverse
administrator. Configuring the dataverse administrator address is done
at the dataverse level: 
``(Your) Dataverse home page > Options page > Settings tab > General subtab > E-Mail Address(es)``

Enable Twitter
---------------------

If your Dataverse Network has been configured for Automatic Tweeting,
you will see an option listed as "Enable Twitter." When you click this,
you will be redirected to Twitter to authorize the Dataverse Network
application to send tweets for you.

To manage the Dataverse Twitter configuration, navigate to:

``Dataverse home page > Options page > Settings tab > Promote Your Dataverse subtab > Sync Dataverse With Twitter``

Once authorized, tweets will be sent for each new dataverse that is
released.

To disable Automatic Tweeting, go to the options page, and click
"Disable Twitter."

Terms Section
=================

Edit Terms for Account Creation
--------------------------------

You can set up Terms of Use that require users with new accounts to
accept your terms before logging in for the first time.

To configure these terms navigate to the Options page:

``Network home page > Options page > Permissions tab > Terms subtab > Account Term of Use``

Enter your required terms as you would like them to appear to users.
HTML, JavaScript, and style tags are permitted. The ``html`` and
``body`` element types are not allowed. Check Enable Terms of Use to
display these terms. Click Save and you are finished. To disable but
preserve your current terms, uncheck the Enable checkbox and save.

Edit Terms for Study Creation
-------------------------------

You can set up Terms of Use for the Network that require users to accept
your terms before they can create or modify studies, including adding
data files. These terms are defined at the network level so they apply
across all dataverses. Users will be presented with these terms the
first time they attempt to modify or create a study during each session.

To configure these terms of use navigate to the Options page:

``Network home page > Options page > Permissions tab > Terms subtab > Deposit Term of Use``

Enter your terms as you would like to display them to the user. HTML,
JavaScript, and style tags are permitted. The ``html`` and ``body``
element types are not allowed. Check Enable Terms of Use and save.
Uncheck Enable Terms of Use and save to disable but preserve existing
terms of use.

Edit Terms for File Download
-----------------------------

You can set up Terms of Use for the Network that require users to accept
your terms before they can download or subset files from the Network.
Since this is defined at the network level it applies to all dataverses.
Users will be presented with these terms the first time they attempt to
download a file or access the subsetting and analysis page each session.

To configure these terms, navigate to the Options page:

``Network home page > Options page > Permissions tab > Terms subtab > Download Term of Use``

Enter the terms as you want them to appear to the user. HTML,
JavaScript, and style tags are permitted. The ``html`` and ``body``
element types are not allowed. Check Enable Terms of Use and save.
Unchecking the checkbox and saving disables the display of the terms but
preserves the current content.

Download Tracking Data
----------------------------

You can view any guestbook responses that have been made in all
dataverses. Beginning with version 3.2 of Dataverse Network, for any
dataverse where the guestbook is not enabled data will be collected
silently based on the logged in user or anonymously. The data displayed
includes user account data or the session id of an anonymous user, the
global ID, study title and filename of the file downloaded, the time of
the download, the type of download and any custom questions that have
been answered. The username/session ID and download type were not
collected in the 3.1 version of DVN. A comma separated values file of
all download tracking data may be downloaded by clicking the Export
Results button.

To manage the Network download tracking data, navigate to:

``Network home page > Options page > Permissions tab > Download Tracking Data subtab > Manage Download Tracking Data table``

Permissions and Users Section
==============================

Manage Network Permissions
---------------------------------------

Permissions that are configured at the network level include:

-  Enabling users to create an account when they create a dataverse.
-  Granting privileged roles to existing users including network
   administrator and dataverse creator.
-  Changing and revoking privileged roles of existing users.

Enabling users to create an account when they create a dataverse
displays a "Create a Dataverse" link on the network home page. New and
unregistered users coming to the site can click on this link, create an
account and a dataverse in one workflow rather than taking two separate
steps involving the network administrator.

Granting a user account network administrator status gives that user
full control over the application as managed through the UI.

Granting a user account dataverse creator status is somewhat a legacy
function since any user who creates a dataverse has this role.

To manage these permissions, navigate to the Manage Network Permissions
table on the Options page:

``Network home page > Options page > Permissions tab > Permissions subtab > Manage Network Permissions table``

Enable account with dataverse creation by checking that option and
saving.

Granting privileged status to a user requires entering a valid, existing
user name, clicking add, choosing the role, then saving changes.

Authorization to access Terms-protected files via the API
--------------------------------------------------------------------

As of DVN v. 3.2, a programmatic API has been provided for accessing DVN
materials. It supports Basic HTTP Auth where the client authenticates
itself as an existing DVN (or anonymous) user. Based on this, the API
determines whether the client has permission to access the requested
files or metadata. It is important to remember however, that in addition
to access permissions, DVN files may also be subject to "Terms of Use"
agreements. When access to such files is attempted through the Web
Download or Subsetting interfaces, the user is presented with an
agreement form. The API however is intended for automated clients, so
the remote party's compliance with the Terms of Use must be established
beforehand. **We advise you to have a written agreement with authorized
parties before allowing them to access data sets, bypassing the Terms of
Use. The authorized party should be responsible for enforcing the Terms
of Use to their end users.**\ Once such an agreement has been
established, you can grant the specified user unrestricted access to
Terms-protected materials on the Network home page > Options page >
PERMISSIONS tab > Permissions subtab, in the "Authorize Users to bypass
Terms of Use" section.

Please consult the Data Sharing section of the Guide for additional
information on the `Data Sharing API <http://guides.thedata.org/book/data-sharing-api>`__.

Create Account
--------------------

There are several ways to create accounts: at the network level by the
network administrator, at the dataverse level by the dataverse
administrator, and by the new user themselves if the option to create an
account when creating a dataverse is enabled.

Accounts created by all methods are equivalent with the exception of
granting dataverse creator status during the create a dataverse
workflow. That status can be granted afterwards by the network
administrator if necessary.

To create an account at the network level, navigate to the Create
Account page from the Options page:

``Network home page > Options page > Permissions tab > Users subtab > Create User link > Create Account page``

Complete the required information denoted by the red asterisk and save.

Manage Users
-------------------

The Manage Users table gives the network administrator a list of all
user accounts in table form. It lists username, full name, roles
including at which dataverse the role is granted, and the current status
whether active or deactivated.

Usernames are listed alphabetically and clicking on a username takes you
to the account page that contains detailed information on that account.
It also provides the ability to update personal details and change
passwords.

The Manage Users table also provides the ability to deactivate a user
account.

To view the Manage Users table navigate to the Options page:

``Network home page > Options page > Permissions tab > Users subtab > Manage Users table``

Manage Groups
--------------------

Groups in the Dataverse Network are a way to identify collections of
users so permissions can be applied collectively rather than
individually. This allows controlling permissions for individuals by
altering membership in the group without affecting permissions of other
members. Groups can be defined by user names or IP addresses.

The Manage Groups table lists information about existing groups in table
form including name, display or friendly name, and group membership.

Clicking on the name takes you to the Edit Group page where the group's
configuration can be changed. It is also possible to create and delete
groups from the Manage Groups table.

To view the Manage Groups table, navigate to the Options page:

``Network home page > Options page > Permissions tab > Groups subtab >
Manage Groups table``

Once on the Groups subtab, viewing the Manage Groups table, you can
create or delete a group.

When creating a group you must choose whether to identify users by
username or by IP address with a Username Group or IP User Group.

With a Username Group, enter an existing username into the edit box,
click the "+" symbol to enter additional users, then save.

With an IP User Group, enter an IP address or domain name into the edit
box. Wildcards can be used by specifying an asterisk (\*) in place of an
IP address octet (eg. 10.20.30.\*), or for the sub-domain or host
portion of the domain name (eg. \*.mydomain.edu).

Last, an optional special feature of the IP User Group is to allow for
an Affiliate Login Service. Effectively this allows for the use of a
proxy to access the Dataverse Network on behalf of a group such as a
University Library where identification and authorization of users is
managed by their proxy service. To enable this feature, enter IP
addresses of any proxy servers that will access Dataverse Network, check
This IP group has an affiliate login service, enter the Affiliate Name
as it will appear on the Dataverse Network Login page, and the Affiliate
URL which would go to the proxy server. Save and you are finished.

Utilities
===========

The Dataverse Network provides the network administrator with tools to
manually execute background processes, perform functions in batch, and
resolve occasional operational issues.

Navigate to the Utilities from the Options page:

``Network home page > Options page > Utilities tab``

Available tools include:

- **Study Utilities** - Create draft versions of studies, release file locks and delete multiple studies by inputting ID's.
- **Index Utilities** - Create a search index. 
- **Export Utilities** - Select files and export them. 
- **Harvest Utilities** - Harvest selected studies from another Network. 
- **File Utilities** - Select files and apply the JHOVE file validation process to them. 
- **Import Utilities** - Import multiple study files by using this custom batch process.
- **Handle Utilities** - Register and re-register study handles.

**Study Utilities**

Curating a large group of studies sometimes requires direct database
changes affecting a large number of studies that may belong to different
dataverses. An example might be changing the distributor name and logo
or the parent dataverse. Since the Dataverse Network employs study
versioning, it was decided that any such backend changes should
increment the affected studies' version. However, incrementing a study's
version is nontrivial as a database update. So, this utility to create a
draft of an existing study was created.

The practice would involve generating a list of study database ID's that
need changing, use the utility to create drafts of those studies, then
run the database update scripts. The result is new, unreleased draft
versions of studies with modifications made directly through the
database. These studies would then need to be reviewed and released
manually.

Due to the transactional nature of study updates, particularly when
uploading large files, it is possible a study update is interrupted such
as during a system restart. When this occurs, the study lock, created to
prevent simultaneous updates while one is already in progress, remains
and the study cannot be edited until it is cleared.

Checking for this condition and clearing it is easy. Open this utility,
check if any locks are listed and remove them. The user should once
again be able to edit their study.

The user interface provides a convenient way to delete individual
studies but when faced with deleting a large number of studies that do
not conveniently belong to a single dataverse, use the Delete utility.

Specify studies by their database id single, as a comma-separated list
(1,7,200, etc.), or as a hyphen-separated range (1-1000, 2005,
2500-2700).

**Index Utilities**

Indexing is the process of making study metadata searchable. The Lucence
search engine used by the Dataverse Network uses file-based indexes.
Normally, any time a study or new study version is released the study
information is automatically indexed. Harvesting also indexes studies in
small batches as they are harvested. Sometimes this does not occur, such
as when the harvest process is interrupted. The index could also become
corrupt for some reason though this would be extremely rare.

The index utility allows for reindexing of studies, dataverses, and the
entire site. Studies and dataverses can be specified by their database
id's alone, in a comma separated list, or in a hyphenated range: 1-1000.
Use index all sparingly, particularly if you have a large site. This is
a single transaction and should not be interrupted or you will need to
start again. A more flexible approach is to determine the lowest and
highest study ID's and index in smaller ranges: 1-1000, 1001-2000, etc.

Note: if for some reason a study change was not indexed, there is an
automatic background process that will detect this, inform the
administrator and will be reindexed once every 24 hours so manually
reindexing is not required.

**Export Utilities**

Export is a background process that normally runs once every 24 hours.
Its purpose is to produce study metadata files in well known formats
such as DDI, DC, MIF, and FGDC that can be used to import studies to
other systems such as through harvesting.

Sometimes it's useful to manually export a study, dataverse, any updated
studies, or all studies. Studies and dataverses are specified by
database id rather than global id or handle.

Export is tied to OAI set creation and Harvesting. To enable harvesting
of a subset of studies by another site, first an OAI set is created that
defines the group of studies. Next, the scheduled export runs and
creates the export files if they're not already available. It also
associates those studies defined by the set with the set name so future
requests for the set receive updates — additions or deletions from the
set. This way remote sites harvesting the set maintain an updated study
list.

If you do not want to wait 24 hours to test harvest a newly created set,
use the export utility. Click "Run Export" to export any changed studies
and associate studies to the set. Exporting studies or dataverses alone
will not associate studies to a set, in those cases Update Harvest
Studies must also be run.

**Harvest Utilities**

The Harvest utility allows for on-demand harvesting of a single study.
First select one of the predefined harvesting dataverses which provide
remote server connection information as well as the local dataverse
where the study will be harvested to. Specify the harvest ID of the
study to be harvested. The harvest id is particular to the study and
server being harvested from. It can be obtained from the OAI protocol
ListIdentifiers command, from the harvest log if previously harvested,
or if from another DVN it takes the form: <OAI set alias>//<global id>.
A Dataverse Network study with ``globalID: hdl:1902.1/10004``, from the OAI
set "My Set", having alias "myset", would have a harvest identifier of:
``myset//hdl:1902.1/10004``

**File Utilities**

The Dataverse Network attempts to identify file types on upload to
provide more information to an end user. It does this by calling a file
type identification library called JHOVE. Though JHOVE is a very
comprehensive library, sometimes a file type may not be recognized or is
similar to another type and misidentified. For these cases we provide an
override mechanism — a list of file extensions and a brief text
description. Since these are created after the files have been uploaded,
this file utility provides a way to re-identify the file types and
furthermore limits this process to specific file types or to studies,
specified by database ID singly, as a comma separated, or as a
hype-separated range.

**Import Utilities**

Importing studies usually is done by harvesting study metadata from a
remote site via the OAI protocol. This causes study metadata to be
hosted locally but files are served by the remote server. The Import
utility is provided for cases where an OAI server is unavailable or
where the intent is to relocate studies and their files to the Dataverse
Network.

At present this requires the help of the network administrator and can
be manually intensive. First, study metadata may need to be modified
slightly then saved in a specific directory structure on the server file
system. Next, the study metadata import format and destination dataverse
is chosen. Last, the top level directory where the study metadata and
files are stored and "Batch Import" is clicked. Because the DDI input
format can be quite complex and usage varies, verify the results are
what's intended.

A single study import function is also provided as a test for importing
your study's metadata syntax but is not meant for actual import. It will
not import associated files.

Before performing a batch import, you must organize your files in the
following manner:

#. If you plan to import multiple files or studies, create a master
   directory to hold all content that you choose to import.
#. Create a separate subdirectory for each study that you choose to
   import.
   The directory name is not important.
#. In each directory, place a file called ``study.xml`` and use that
   file to hold the XML-formatted record for one study.
   Note: Do not include file description elements in
   the ``study.xml`` file. Including those fields results in the
   addition of multiple blank files to that study.
#. Also place in the directory any additional files that you choose to
   upload for that study.

For an example of a simple study DDI, refer to the Metadata Reference
section of the appendix.

**Handle Utilities**

When a study is created, the global ID is first assigned, then
registered with handle.net as a persistent identifier. This identifier
becomes part of the study's citation and is guaranteed to always resolve
to the study. For the study with global ID, hdl:1902.1/16598 or handle
1902.1/16596, the URL in the citation would be:
`http://hdl.handle.net/1902.1/16598 <http://hdl.handle.net/1902.1/16598>`__.

If for any reason a study is created and not registered or is registered
in a way that needs to be changed, use the Handle utility to either
register currently unregistered studies or to re-register all registered
studies.

Web Statistics
===============

The Dataverse Network provides the capability to compile and analyze
site usage through Google Analytics. A small amount of code is embedded
in each page so when enabled, any page access along with associated
browser and user information is recorded by Google. Later analysis of
this compiled access data can be performed using the `Google Analytics <http://www.google.com/analytics/>`__ utility.

Note: Access to Google Analytics is optional. If access to this utility
is not configured for your network, in place of the Manage Web Usage
menu option is a message
stating: ``Google Analytics are not configured for this Network.``

**To enable Google Analytics:**

#. Create a Gmail account.
#. Go to `Google Analytics <http://www.google.com/analytics/>`__ and create a profile for the server or website domain. You will
   be assigned a Web Property ID.
#. Using the Glassfish Admin console, add a JVM option and assign it the value of the newly assigned Web Property ID: 
   ``Ddvn.googleanalytics.key=``
#. Restart Glassfish.
#. It takes about 24 hours after installation and set up of this option for tracking data to become available for use.

Note: Google provides the code necessary for tracking. This has already
been embedded into the Dataverse Network but not the Web Property ID.
That is configured as a JVM option by the network admin when enabling
this feature.

**To view Web Statistics, navigate to:**

- Network home page > Options page > Settings tab > General subtab > Web Statistics
- You will be redirected to `Google Analytics <http://www.google.com/analytics/>`__. Log in using your Gmail account used to
  create the profile.

Data Sharing
===================

Data Sharing API
-----------------

As of version 3.0, a new API for programmatic access to the Dataverse
Network data and metadata has been added. The API allows a remote,
non-Dataverse Network archive/application to search the holdings and
download files from a Dataverse Network installation.

The API documentation is available
`here <https://sourceforge.net/projects/dvn/files/dvn/3.0/dvnapi_v1_0.pdf>`__.
